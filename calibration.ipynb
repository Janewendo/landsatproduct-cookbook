{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f431724-e20c-4a49-84d7-8c3169915ce2",
   "metadata": {},
   "source": [
    "---\n",
    "title: Calibrate your physical model\n",
    "authors:\n",
    "  - name: Jianwen Du\n",
    "    affiliations:\n",
    "      - id: UoA\n",
    "        institution: University of Arizona\n",
    "        department: Hydrology and Atmospheric Sciences\n",
    "license: Apache 2.0\n",
    "date: 2025â€‘08â€‘07\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca65bd8-0f77-4322-a722-b0c901f6e758",
   "metadata": {},
   "source": [
    "#### This is a notebook for calibrating your physical model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801fc78-b922-491e-95bb-2be082f1ed08",
   "metadata": {},
   "source": [
    "## Why to Calibrate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a2fba-ec55-434e-a119-ac2181c526b3",
   "metadata": {},
   "source": [
    "Calibration of a physical model is the process of tuning its parameters to ensure its outputs accurately match real-world measurements. It's about bridging the gap between theoretical calculations and physical reality. You need to calibrate a physical model because it's inherently a simplification of a real-world system and often contains parameters with unknown or uncertain values. Calibration is the rigorous process of adjusting these parameters to minimize the discrepancy between the model's output and experimental observations. The primary goal is to improve the model's predictive accuracy, transforming it from a theoretical construct into a reliable tool for analysis and design. This is crucial not only for a single model's accuracy but also for ensuring consistency when multiple models must work together, a process known as cross-calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b22a95-a455-4e46-a80d-9e3df4db4c44",
   "metadata": {},
   "source": [
    "## What Do You Need?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f05db81-d962-421d-907f-c5fd0208a282",
   "metadata": {},
   "source": [
    "To calibrate a physical model, you need a few key components:\n",
    "\n",
    "1. A Physical Model: This could be a set of mathematical equations or a simulation software (e.g., reactive transport model).\n",
    "2. Tunable Parameters: The specific \"knobs\" in your model that you can adjust. Examples include a reaction rate constant.\n",
    "3. Experimental Data: High-quality, reliable measurements from the real-world system or a controlled experiment. This is your \"ground truth\" that you want the model to match.\n",
    "4. An Objective Function: A metric that quantifies the error or difference between the model's predictions and the experimental data. They can be Sum of Squared Errors (SSE), Root Mean Squared Error (RMSE), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90284d77-ca6d-4673-9c39-312a6f02739f",
   "metadata": {},
   "source": [
    "## How to Calibrate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ef392-712b-48a6-80b4-b26bce2eb831",
   "metadata": {},
   "source": [
    "There are two main ways to turn the knobs and lower your error score:\n",
    "\n",
    "1. By Hand (Trial and Error): You can manually change a setting, run the model, check the error, and repeat the process. But it's slow and might not be perfect.\n",
    "\n",
    "2. Smart Computer Search (Optimization): The much better way is to let a computer do the work. You use an optimization algorithm that automatically tries thousands of different settings to find the combination that results in the lowest possible error score. It's fast, efficient, and finds the best possible tune-up for your model.\n",
    "\n",
    "<div style=\"background-color:#E3F2FD; border:1px solid #2196F3; border-radius:5px; padding:10px; font-family:sans-serif; color:#2196F3;\">\n",
    "<b>ðŸ’¡ Note:</b> \n",
    "Optimization Algorithms: Automated algorithms are used to search the parameter space efficiently. These are broadly categorized into:\n",
    "\n",
    "* Gradient-Based Methods: These algorithms (e.g., Levenberg-Marquardt) use the gradient of the objective function to find the minimum error value quickly. They are highly efficient when gradients are available.\n",
    "\n",
    "* Gradient-Free (Direct Search) Methods: These algorithms (e.g., Nelder-Mead, Genetic Algorithms) do not require gradient information, making them essential for complex or \"black-box\" simulations.\n",
    "\n",
    "* Bayesian Calibration: This is a sophisticated statistical method that treats parameters as probability distributions rather than single values. It provides not only the most likely parameter values but also quantifies the uncertainty associated with them.\n",
    "\n",
    "* Cross-Calibration: This is the process of calibrating one model against another that is considered a trusted reference or \"gold standard.\" Instead of using direct experimental data as the ground truth, the output from the reference instrument is used. The goal is to ensure the outputs of different models are consistent and comparable, which is vital for large sensor networks or comparing results from different simulation suites.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f0f67-0a45-43ca-9bfb-87279290f2b5",
   "metadata": {},
   "source": [
    "## How do you tell if your model is calibrated? âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1c9f0-a43e-4994-ba76-4d32cc0bba2e",
   "metadata": {},
   "source": [
    "1. Look at the Leftover Errors: After calibration, check the small differences that are still left between your model's predictions and the real data. If you plot these \"leftover errors,\" they should look completely random. If they show a clear pattern (like a curve), it means your model is still missing something important.\n",
    "\n",
    "2. The Final Test (Validation): The best test is to use your newly calibrated model on a fresh set of real-world data that it has never seen before. If the model's predictions are still accurate on this new data, you can be confident that your calibration was a success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfbc39e5-4e3c-4345-b65d-9e531160c910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8c0d25954244899aeb802f95ccf76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.5, description='slope', max=5.0), FloatSlider(value=0.0, descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, let's install ipywidgets for the interactive sliders\n",
    "!pip install -q ipywidgets\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "# 1. Create the sample \"Experimental Data\"\n",
    "np.random.seed(0)\n",
    "x_data = np.linspace(0, 10, 20)\n",
    "true_slope = 2.5\n",
    "true_intercept = 1.5\n",
    "y_data = true_slope * x_data + true_intercept + np.random.normal(0, 2, size=x_data.shape)\n",
    "\n",
    "# 2. Define a function to plot the data and our adjustable model\n",
    "def plot_model(x, y, slope, intercept):\n",
    "    \"\"\"Plots the experimental data against the model line defined by slope and intercept.\"\"\"\n",
    "    y_model = slope * x + intercept\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, y, 'o', label='Experimental Data', markersize=8, color='royalblue')\n",
    "    plt.plot(x, y_model, '-', label='Adjustable Model', linewidth=3, color='red')\n",
    "    \n",
    "    # Calculate and display the RMSE as our objective function score\n",
    "    rmse = np.sqrt(np.mean((y - y_model)**2))\n",
    "    plt.title(f'Comparison of Model vs. Data (RMSE: {rmse:.2f})', fontsize=16)\n",
    "    \n",
    "    plt.xlabel('Independent Variable', fontsize=12)\n",
    "    plt.ylabel('Dependent Variable', fontsize=12)\n",
    "    plt.ylim(min(y_data)-2, max(y_data)+2)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "# 3. Create the interactive plot!\n",
    "# The 'interact' function automatically creates sliders for the numerical arguments.\n",
    "interact(plot_model, x=fixed(x_data), y=fixed(y_data), slope=(0.0, 5.0, 0.1), intercept=(-5.0, 5.0, 0.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f8141-54da-4e16-b0f4-57945485f849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
